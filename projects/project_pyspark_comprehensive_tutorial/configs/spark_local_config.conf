# Spark Configuration for Local Development (6-core macOS)
# Optimized for datasets < 10GB

# Application Settings
spark.app.name=PySpark-Tutorial-Local
spark.master=local[6]  # Use all 6 cores

# Memory Settings (Conservative for local development)
spark.driver.memory=3g
spark.driver.maxResultSize=1g
spark.executor.memory=2g
spark.executor.memoryFraction=0.8

# Local Development Optimizations
spark.sql.adaptive.enabled=true
spark.sql.adaptive.coalescePartitions.enabled=true
spark.sql.adaptive.coalescePartitions.minPartitionNum=2
spark.sql.adaptive.coalescePartitions.initialPartitionNum=12  # 2x cores

# Arrow Settings for pandas integration
spark.sql.execution.arrow.pyspark.enabled=true
spark.sql.execution.arrow.maxRecordsPerBatch=10000

# Serialization
spark.serializer=org.apache.spark.serializer.KryoSerializer

# UI and Logging
spark.ui.port=4040
spark.sql.adaptive.logLevel=WARN
spark.eventLog.enabled=false

# Local file system optimizations
spark.sql.files.maxPartitionBytes=128MB
spark.sql.files.openCostInBytes=4MB

# Disable dynamic allocation for local mode
spark.dynamicAllocation.enabled=false
